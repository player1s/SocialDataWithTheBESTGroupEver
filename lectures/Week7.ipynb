{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Last week you had an intro to classification tasks and decision trees. You worked on a model to predict criminal recidivism and made a few visualizations along the way. \n",
    "\n",
    "Some of you asked: why Machine Learning? And, even though modeling is part of analysing data and predictions are a huge part of how people use data nowadays, there is something more important to it: visualization are not only powerful to study data, they are also great to understand models. We needed that little extra Machine Learning to explore another way of using visualizations. \n",
    "\n",
    "Today, we will do exactly this! The purpose of today's class is threefold: \n",
    "\n",
    "1. To explore the data I gave you last week with **interactive visualizations**;\n",
    "2. To **visualize the results** on criminal recidivism of your machine learning model;\n",
    "3. To **debias** the results you obtained via two methods (and a bit of visualization along the way). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Interactive visualizations with Bokeh\n",
    "\n",
    "Until today we have worked with static data visualization. However, exploratory data analysis means to be able to explore the multi-faceted nature of data and *interactive dataviz* is a handy tool to do it! It allows to play with the data: Toggle the view. Zoom. Drag. Show more details. All those things. Those are a key part of modern data visualization. \n",
    "\n",
    "To really master interactive visualizations, you should check out methods in JavaScript, especially [D3](https://d3js.org). Given that we only have 5ECTS for this class, we unfortunately don't have time for that. But luckily Python has some pretty good options for interactive visualizations. [Here](https://mode.com/blog/python-interactive-plot-libraries/), you can find some of them.\n",
    "\n",
    "Today, we'll explore [`Bokeh`](https://docs.bokeh.org/en/latest/), which provides lots of nice interactive funtionalities to Python. To work with Bokeh, we first need to do some preparation:\n",
    "1. If you haven't installed it yet please do so. You can simply follow [these steps](https://docs.bokeh.org/en/latest/docs/first_steps/installation.html)\n",
    "2. To include Bokeh in your notebooks you can follow the [Bokeh: Using with Jupyter](https://docs.bokeh.org/en/latest/docs/user_guide/jupyter.html#userguide-jupyter-notebook) guide. Come back to this one when you need it\n",
    "3. We aim to give you a gentle start with Bokeh and I am going to include more example codes than usual in the follwing. However, to get a sense of how things work, I suggest you surf the web, find a Bokeh tutorial and scan through it. Also click around a bit in [the official docs](https://docs.bokeh.org/en/latest/docs/user_guide.html#userguide).\n",
    "\n",
    "In the exercises below, we will use the data from [GitHub](https://raw.githubusercontent.com/suneman/socialdata2022/main/files/recidivism_dataset_sub.csv):\n",
    "1. Load the data and select the columns as in Week 6, Exercise 3.1\n",
    "2. Preprocess the data as in Week 6, Exercise 3.2.\n",
    "\n",
    "Ok, let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, Legend, HoverTool, Title\n",
    "from bokeh.io import output_notebook, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "recidivism = pd.read_csv('https://raw.githubusercontent.com/suneman/socialdata2022/main/files/recidivism_dataset_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "\n",
    "# 0. drop all columns except 'age', 'sex', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'is_recid',\n",
    "#                            'days_b_screening_arrest', 'c_charge_degree', 'two_year_recid'\n",
    "\n",
    "recidivism = recidivism[['age', 'sex', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'is_recid',\n",
    "                         'days_b_screening_arrest', 'c_charge_degree', 'two_year_recid']]\n",
    "\n",
    "# 1. filter out records where the `is_recid` feature is not known (i.e. where it is equal to -1)\n",
    "\n",
    "recidivism = recidivism.drop(recidivism[recidivism.is_recid == -1].index)\n",
    "\n",
    "# 2. only keep records that cause jail time\n",
    "\n",
    "recidivism = recidivism.drop(recidivism[recidivism.c_charge_degree == 'O'].index)\n",
    "\n",
    "# 3. only keep records that have between $-30$ and $30$ days between the arrest and screening\n",
    "\n",
    "recidivism = recidivism.drop(recidivism[(recidivism.days_b_screening_arrest <= -30) | (recidivism.days_b_screening_arrest >= 30) | \\\n",
    "    (recidivism.days_b_screening_arrest.isna())].index)\n",
    "\n",
    "# 4. drop `is_recid`, `c_charge_degree`, `days_b_screening_arrest` for the upcoming analysis\n",
    "\n",
    "recidivism = recidivism.drop(columns = ['is_recid', 'c_charge_degree', 'days_b_screening_arrest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercise 1.1:* Interactive data exploration. The aim of this exercise is to compare bar plots for different races. Each bar plot will have age on the x-axis and number of samples in the data on the y-axis. Follow the steps below for success:\n",
    ">\n",
    "> * Compute the number of samples by age for each race. You should end up with a dataframe that looks like [this](https://github.com/suneman/socialdata2022/blob/main/files/bokeh-df1.png).\n",
    "> * Convert your `DataFrame` to Bokeh `ColumnDataSource`.\n",
    "> * Create an empty figure, you can find the a guide to define a figure in Bokeh online. Here, a little help:\n",
    "> ```python\n",
    "p = figure(ADD_PARAMS_HERE) #p is a standard way to call figures in Bokeh\n",
    "#do not forget to add attributes to the figure, e.g. title, axis names, etc.\n",
    "> ```\n",
    "> * Add bars by using `p.vbar()` as follows:\n",
    "> ```python\n",
    "    bar ={} # to store vbars \n",
    "    # here we will do a for loop to create a bar for each race\n",
    "    for indx,i in enumerate(races):\n",
    "         bar[i] = p.vbar(x=ADD_AGE_COLUMN_NAME,  top=i, source= ADD_YOUR_DATA, legend_label=i, ..., muted = ...) \n",
    "> ```\n",
    "> * Make your legend interactive and display the figure:\n",
    "> ```python\n",
    "    p.legend.click_policy=\"mute\" #assigns the click policy (you can try to use ''hide')\n",
    "    show(p) #displays your plot\n",
    "> ```\n",
    "> * You will notice that the legend appears in the middle of the figure (and it ocludes some of the data). In order to fix this look into [this guide](https://stackoverflow.com/questions/26254619/position-of-the-legend-in-a-bokeh-plot) as a start. Below are some code snippets that you can use to deal with this problem (but read the guide first):\n",
    "> ```python\n",
    "    items = [] # for the custom legend // you need to figure out where to add it\n",
    "    items.append((i, [bar[i]])) # figure out where to add it\n",
    "    legend = Legend(items=..., location=.....) # figure out where to add it\n",
    "    p.add_layout(...., ...) # figure where to add it\n",
    "    # if you read the guide, it will make sense :)\n",
    "> ```\n",
    "> * And now you have it! You can play with colors and other parameters to make it as you like, but first describe your plot. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.1 Preprocessing\n",
    "\n",
    "# Compute the number of samples by age for each race\n",
    "\n",
    "recidivism_by_age_each_race = recidivism.groupby(['age', 'race']).agg({'sex':'count'}).sort_values(by=['age', 'race'])\\\n",
    "    .rename(columns={'sex':'Counts'}).reset_index()\n",
    "\n",
    "recidivism_by_age_each_race = recidivism_by_age_each_race.pivot(index = 'age', columns='race', values = 'Counts').reset_index()\n",
    "\n",
    "# Convert your `DataFrame` to Bokeh `ColumnDataSource`.\n",
    "recidivism_by_age_each_race = ColumnDataSource(recidivism_by_age_each_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1272\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  const JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1272\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1272\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 1.1 Plotting\n",
    "\n",
    "# Create an empty Bokeh figure\n",
    "p = figure(title = 'Number of People who recomitted a Crime by Age')\n",
    "\n",
    "# create the bar chart (task to move the legend is commeted out as not needed)\n",
    "\n",
    "bar = {}\n",
    "# items = []\n",
    "for indx,i in enumerate(np.unique(recidivism['race'].values)):\n",
    "    bar[i] = p.vbar(x='age',  top=i, source= recidivism_by_age_each_race, legend_label=i, muted = True)\n",
    "    # items.append((i, [bar[i]])) \n",
    "\n",
    "p.legend.click_policy=\"mute\"\n",
    "# legend = Legend(items=items, location=(10, -25))\n",
    "# p.add_layout(legend, 'right')\n",
    "p.add_layout(Title(text=\"Age\", align=\"center\"), \"below\")\n",
    "p.add_layout(Title(text=\"Count\", align=\"center\"), \"left\")\n",
    "\n",
    "show(p)\n",
    "output_notebook()\n",
    "\n",
    "del bar, i, indx, p, recidivism_by_age_each_race #, items, legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you observe?**\n",
    "- barely any native american or asian people\n",
    "- african american, caucasian -> skewed to the left -> so more young people (hispanics similar trend, but not as clearly)\n",
    "- the more crimes the clearer the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "During Week 6 I asked you to visualize a bar plot with the fraction of recommitted crimes over total number of records per race, e.g. the number of recommitted crimes of African-Americans over the total number of crimes of African-Americans, etc. You should have obtained something like [this](https://github.com/suneman/socialdata2022/blob/main/files/frac_recommit_race.png). If we look at this plot we observe that all races but Asian have fraction of recommitted crimes above $30\\%$, and African-Americans have the highest fraction, i.e. above $50\\%$. However, is this the whole story? Let's have a look at this data from a different angle!\n",
    "\n",
    "> *Exercise 1.2:* fraction of crimes - a different perspective. In this exercise, we are going to create an interactive scatter plot, where each point is a race, with position given by the number of total samples in the race category on the x-axis and the number of recommitted crimes in the race category on the y-axis. Moreover, each point will have a size given by the fraction computed in Week 6. Follow these steps for success:\n",
    "> * Create a `DataFrame` with `race` as index and the following columns: \n",
    ">     * `n_samples`, i.e. number of samples for each race,\n",
    ">     * `n_rec_crimes`, i.e. number of recommitted crimes for each race,\n",
    ">     * `frac_crimes`, i.e. `n_rec_crimes/n_samples`.\n",
    "> * Convert the dataframe into a `ColumnDataSource` and create an empty figure.\n",
    "> * Add points in your figure by using \n",
    "> ```python\n",
    ">   p.circle(ADD_X_COLUMN,ADD_Y_COLUMN, size=..., source=..., ...)\n",
    "> ```\n",
    "> * Add a `HoverTool()` so that when hovering over a circle both race and size are displayed.\n",
    "> * You can change colors of the data points by passing an additional color column to `p.circle()`.\n",
    "> * And now a couple of questions: Explain what you observe. What does this plot shows that the fraction of crimes alone didn't? Do you think the data we are using is representative? What could be some possible issues with this data? \n",
    "\n",
    "Once answered the questions above, **take a minute and discuss** your thoughts with your neighbour or one of your group members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.2\n",
    "\n",
    "# Preprocessing -> create the dataframe\n",
    "recidivism_race = recidivism.groupby(['race', 'two_year_recid']).agg({'two_year_recid':'count'}).\\\n",
    "    rename(columns={'two_year_recid':'Count'}).reset_index()\n",
    "\n",
    "n_samples = recidivism_race.groupby(['race']).agg({'Count':'sum'}).rename(columns={'Count':'n_samples'}).reset_index()\n",
    "n_rec_crimes = recidivism_race[recidivism_race['two_year_recid'] == 1].rename(columns={'Count':'n_rec_crimes'})\n",
    "\n",
    "recidivism_race = pd.concat([n_rec_crimes.set_index('race'),n_samples.set_index('race')], axis=1, join='inner')\n",
    "\n",
    "recidivism_race['frac_crimes'] = (recidivism_race['n_rec_crimes']/ recidivism_race['n_samples'])*100\n",
    "recidivism_race = recidivism_race.drop(columns = ['two_year_recid'])\n",
    "\n",
    "index = recidivism_race.index\n",
    "\n",
    "recidivism_race = recidivism_race = ColumnDataSource(recidivism_race)\n",
    "recidivism_race.add(index, 'race')\n",
    "\n",
    "del n_rec_crimes, n_samples, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"8c355490-96ae-4e6d-9f2f-3df678830d42\" data-root-id=\"1274\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n    \n  const docs_json = {\"198f8961-b6af-47e9-9879-42cff74b6890\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1285\"},{\"id\":\"1311\"}],\"center\":[{\"id\":\"1288\"},{\"id\":\"1292\"}],\"left\":[{\"id\":\"1289\"},{\"id\":\"1312\"}],\"renderers\":[{\"id\":\"1300\"}],\"title\":{\"id\":\"1275\"},\"toolbar\":{\"id\":\"1294\"},\"x_range\":{\"id\":\"1277\"},\"x_scale\":{\"id\":\"1281\"},\"y_range\":{\"id\":\"1279\"},\"y_scale\":{\"id\":\"1283\"}},\"id\":\"1274\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis\":{\"id\":\"1285\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1288\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1305\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1286\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1307\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1307\"},\"group\":null,\"major_label_policy\":{\"id\":\"1308\"},\"ticker\":{\"id\":\"1286\"}},\"id\":\"1285\",\"type\":\"LinearAxis\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1304\"},\"group\":null,\"major_label_policy\":{\"id\":\"1305\"},\"ticker\":{\"id\":\"1290\"}},\"id\":\"1289\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1281\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#1f77b4\"},\"hatch_alpha\":{\"value\":0.2},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"field\":\"frac_crimes\"},\"x\":{\"field\":\"n_samples\"},\"y\":{\"field\":\"n_rec_crimes\"}},\"id\":\"1299\",\"type\":\"Circle\"},{\"attributes\":{\"align\":\"center\",\"coordinates\":null,\"group\":null,\"text\":\"Number of recommitted Crimes by each Race\"},\"id\":\"1312\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1308\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1309\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1290\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1277\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data\":{\"frac_crimes\":{\"__ndarray__\":\"1HWL0IoiSkDOOeecc845QPPx/DYimENAIBAIBAKBQkC66KKLLrpGQLiP4D6C+0FA\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[6]},\"n_rec_crimes\":[1658,8,821,188,5,123],\"n_samples\":[3172,31,2095,508,11,342],\"race\":[\"African-American\",\"Asian\",\"Caucasian\",\"Hispanic\",\"Native American\",\"Other\"]},\"selected\":{\"id\":\"1310\"},\"selection_policy\":{\"id\":\"1309\"}},\"id\":\"1273\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"Race\",\"@race\"],[\"Fraction of total Crimes [%]\",\"@frac_crimes\"]]},\"id\":\"1293\",\"type\":\"HoverTool\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1273\"},\"glyph\":{\"id\":\"1297\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1299\"},\"nonselection_glyph\":{\"id\":\"1298\"},\"view\":{\"id\":\"1301\"}},\"id\":\"1300\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis\":{\"id\":\"1289\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1292\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1283\",\"type\":\"LinearScale\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"field\":\"frac_crimes\"},\"x\":{\"field\":\"n_samples\"},\"y\":{\"field\":\"n_rec_crimes\"}},\"id\":\"1297\",\"type\":\"Circle\"},{\"attributes\":{\"tools\":[{\"id\":\"1293\"}]},\"id\":\"1294\",\"type\":\"Toolbar\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"hatch_alpha\":{\"value\":0.1},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"field\":\"frac_crimes\"},\"x\":{\"field\":\"n_samples\"},\"y\":{\"field\":\"n_rec_crimes\"}},\"id\":\"1298\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1310\",\"type\":\"Selection\"},{\"attributes\":{\"source\":{\"id\":\"1273\"}},\"id\":\"1301\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1279\",\"type\":\"DataRange1d\"},{\"attributes\":{\"align\":\"center\",\"coordinates\":null,\"group\":null,\"text\":\"Number of Samples for each Race\"},\"id\":\"1311\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1304\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"Fraction of Recomitted Crimes by Race\"},\"id\":\"1275\",\"type\":\"Title\"}],\"root_ids\":[\"1274\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.2\"}};\n  const render_items = [{\"docid\":\"198f8961-b6af-47e9-9879-42cff74b6890\",\"root_ids\":[\"1274\"],\"roots\":{\"1274\":\"8c355490-96ae-4e6d-9f2f-3df678830d42\"}}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1274"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1367\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  const JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1367\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1367\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 1.2\n",
    "\n",
    "# plotting\n",
    "\n",
    "p = figure(tools='hover', title = 'Fraction of Recomitted Crimes by Race')\n",
    "\n",
    "p.circle('n_samples','n_rec_crimes', size = 'frac_crimes', source= recidivism_race)\n",
    "\n",
    "hover = p.select(dict(type=HoverTool))\n",
    "hover.tooltips = [\n",
    "    (\"Race\", \"@race\"),\n",
    "    (\"Fraction of total Crimes [%]\", \"@frac_crimes\"),\n",
    "    ]\n",
    "\n",
    "p.add_layout(Title(text=\"Number of Samples for each Race\", align=\"center\"), \"below\")\n",
    "p.add_layout(Title(text=\"Number of recommitted Crimes by each Race\", align=\"center\"), \"left\")\n",
    "\n",
    "# add HoverTool() ->   when hovering over a circle both race and size are displayed\n",
    "\n",
    "show(p)\n",
    "output_notebook()\n",
    "\n",
    "del hover, p, recidivism_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.2 Explain what you observe.**\n",
    "<br> What does this plot shows that the fraction of crimes alone didn't? -> the amount of crimes\n",
    "<br> Do you think the data we are using is representative? -> not for all races\n",
    "<br> What could be some possible issues with this data? -> sample size for some races to small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Ok, it is now time to uncover where this data is coming from. <b>Only click on this cell to open it after you have completed the exercise above</b></summary>\n",
    "    The data we are using is related to:\n",
    "    <ul>\n",
    "        <li> <b>COMPAS</b> (Correctional Offender Management Profiling for Alternative Sanctions), a <a href=https://towardsdatascience.com/compas-case-study-fairness-of-a-machine-learning-model-f0f804108751>popular commercial algorithm</a> used by judges and parole officers for scoring criminal defendantâ€™s likelihood of reoffending (recidivism).  </li>\n",
    "        <li> Multiple works have shown that the algorithm is biased towards non-caucasian people. <b>ProPublica</b> has published an <a href=https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm>extensive work</a> on the topic. </li>\n",
    "    </ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visualize the results of a Machine Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we had a deeper look at the recidivism dataset and the visualizations we created highlighted some possible issues/imbalances with the data and especially with race. \n",
    "\n",
    "If you had a look at the hidden information cell above, now you know what the problems are with this dataset and with using it to predict recidivism. During Week 6, you trained a classification model to predict criminal recidivism on this data. Now, a question might rise... Is your model biased? If yes, can you do anything about it?\n",
    "\n",
    "You will now use visualization to better understand the results of your model. This is one of the reasons why visualization is so powerful. Not only it allows us to explore data and create an understanding of the different aspects of it, but it also allows us to understand ML models and their performance!\n",
    "\n",
    "In the next exercise, use the model you have trained/tested in Week 6 by using only the columns selected in Week 6, Exercise 3.1 and by preprocessing as in Exercise 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercise 2:* Evaluating the quality of predictions. One of the simplest ways to get a glimpse into the performance of an classification model is to look at the [Confustion Matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62).\n",
    ">\n",
    "> * Create a confusion matrix that evaluates the performance of your model. What do you observe?\n",
    "> * Now, create a confusion matrix for specific groups:\n",
    ">    * Take targets and predictions only for *Caucasians*,\n",
    ">    * Take targets and predictions only for *African-Americans*.\n",
    ">    * Create a confusion matrix for each group. What do you see when you compare the two confusion matrices? Explain in your own words how this might affect the overall fairness of your model.\n",
    "\n",
    "Again, after giving an answer to the questions above, **take a minute and discuss** your thoughts with your neighbour or one of your group members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> Exercise 2 interpretation hint <b>(Only open after you have completed the exercise above)</b></summary>\n",
    "    <ul>\n",
    "        <li>It seems that our model has higher number of <b>False-Positives</b> or <b>False-Negatives</b> for different groups of people. Go back to Exercise 2 if you did not spot this difference and think at the related implication. </li>\n",
    "      <li>Several researchers also noticed this issue. The following essay by Ellora Thadaney Israni describes the potential issues with the algorithm and data: <a href = https://www.nytimes.com/2017/10/26/opinion/algorithm-compas-sentencing-bias.html> When an Algorithm Helps Send You to Prison </a> (If you don't have access to it you can find the article on DTU Learn -> Course Content -> Content -> Lecture 7 reading)</li>\n",
    "    </ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 6: 3.2.3 Feature Engineering -> one hot encoding applied on the race column and label encoding on the sex column\n",
    "\n",
    "# Get one hot encoding of column race\n",
    "one_hot = pd.get_dummies(recidivism['race'], prefix = 'race')\n",
    "# Drop column race as it is now encoded\n",
    "recidivism = recidivism.drop('race',axis = 1)\n",
    "# Join the encoded df\n",
    "recidivism = recidivism.join(one_hot)\n",
    "\n",
    "# label encoding on the sex column (0 -> Female; 1 -> Male)\n",
    "recidivism['sex'] = recidivism['sex'].astype('category')\n",
    "recidivism['sex'] = recidivism['sex'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if equal samples of each target value:\n",
      "(array([0, 1], dtype=int64), array([1962, 1962], dtype=int64))\n",
      "(array([0, 1], dtype=int64), array([841, 841], dtype=int64))\n",
      "Feature importance of 1. Random Forest Classifier Model: \n",
      "age                      0.522835\n",
      "priors_count             0.321437\n",
      "juv_other_count          0.034528\n",
      "sex                      0.028832\n",
      "juv_misd_count           0.024872\n",
      "race_African-American    0.021073\n",
      "juv_fel_count            0.018079\n",
      "race_Caucasian           0.010978\n",
      "race_Hispanic            0.008155\n",
      "race_Other               0.006027\n",
      "race_Asian               0.001970\n",
      "race_Native American     0.001216\n",
      "dtype: float64\n",
      "Mean Absolute Error of 1. Random Forest Classifier Model: 0.38 degrees.\n",
      "Accuracy of 1. Random Forest Classifier Model: 0.62\n",
      "Classification Report of 1. Random Forest Classifier Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       841\n",
      "           1       0.63      0.60      0.61       841\n",
      "\n",
      "    accuracy                           0.62      1682\n",
      "   macro avg       0.62      0.62      0.62      1682\n",
      "weighted avg       0.62      0.62      0.62      1682\n",
      "\n",
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 1000, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Best parameters based on RandomizedSearchCV: \n",
      "{'n_estimators': 338, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 50, 'bootstrap': True}\n",
      "Model Performance\n",
      "Average Error: 0.3722 degrees.\n",
      "Accuracy = 0.63%.\n",
      "Model Performance\n",
      "Average Error: 0.3448 degrees.\n",
      "Accuracy = 0.66%.\n",
      "Improvement of the model based on RandomizedSearchCV 4.76%.\n",
      "parameters for param_grid: {'n_estimators': 338, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 50, 'bootstrap': True}\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "{'bootstrap': True, 'max_depth': 70, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 1740}\n",
      "Model Performance\n",
      "Average Error: 0.3430 degrees.\n",
      "Accuracy = 0.66%.\n",
      "Improvement of the model based on GridSearchCV 4.76%.\n"
     ]
    }
   ],
   "source": [
    "# Week 6: Exercise 3.3\n",
    "\n",
    "# 3.3.1\n",
    "\n",
    "# a)\n",
    "# split the data set in train and test set (70/30 split) -> balanced data set grab equal amount of each target value\n",
    "# train_test_split by sklearn\n",
    "\n",
    "X = recidivism.loc[:, ~recidivism.columns.isin(['two_year_recid'])]\n",
    "#0 = defendant did not recommit a crime within two years; 1 = the defendant recommitted a crime within two years\n",
    "y = recidivism['two_year_recid']\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, stratify=y_res, random_state=42) \n",
    "\n",
    "# to check if equal amount of each target value\n",
    "print('Check if equal samples of each target value:')\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n",
    "\n",
    "# b)\n",
    "# fit randomforest or DecisionTreeClassifier\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 3.3.2\n",
    "\n",
    "# Are your results tied to the specific training data/hyperparameter set you used? -> I guess\n",
    "\n",
    "# feature importance\n",
    "feature_imp = pd.Series(rf.feature_importances_,index=X.columns).sort_values(ascending=False)\n",
    "print('Feature importance of 1. Random Forest Classifier Model: ')\n",
    "print(feature_imp) \n",
    "# drop features with low importance -> X = recidivism.loc[:, recidivism.columns.isin(['age', 'priors_count'])] might be enough\n",
    "\n",
    "# prediction (needs to be rounded, so its similar to the features again)\n",
    "y_pred=rf.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error of 1. Random Forest Classifier Model:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy of 1. Random Forest Classifier Model:\",metrics.accuracy_score(y_test, y_pred).round(2))\n",
    "\n",
    "# precision and recall\n",
    "print('Classification Report of 1. Random Forest Classifier Model')\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# !!! Confusion matrix would be also helpful !!!\n",
    "\n",
    "# 3.2.3 Results toed to specific training data/ hyperparameter set?\n",
    "\n",
    "# RandomizedSearchCV -> recompute the performance metric above with the hyperparameters found\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "print(rf.get_params())\n",
    "\n",
    "# n_estimators = number of trees in the foreset\n",
    "# max_features = max number of features considered for splitting a node\n",
    "# max_depth = max number of levels in each decision tree\n",
    "# min_samples_split = min number of data points placed in a node before the node is split\n",
    "# min_samples_leaf = min number of data points allowed in a leaf node\n",
    "# bootstrap = method for sampling data points (with or without replacement)\n",
    "\n",
    "\n",
    "# Random Hyperparameter Grid\n",
    "\n",
    "# Number of trees in random forest (current random forest model n_estimators = 1000)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 1000)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf_reg = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(estimator = rf_reg, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42\\\n",
    "    , n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters based on RandomizedSearchCV: ')\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "### Evaluate Random Search\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    errors = abs(y_pred - y_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred).round(2)\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "base_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "print('Improvement of the model based on RandomizedSearchCV {:0.2f}%.'.format(100 * (random_accuracy - base_accuracy) / base_accuracy))\n",
    "\n",
    "# Week 6: continuation of 3.2.3\n",
    "\n",
    "print(f'parameters for param_grid: {rf_random.best_params_}')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [70],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [4],\n",
    "    'min_samples_split': [2],\n",
    "    'n_estimators': [1740]\n",
    "}\n",
    "# Create a based model\n",
    "rf_grid = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf_grid, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)\n",
    "\n",
    "print('Improvement of the model based on GridSearchCV {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best grid: \n",
      "[[567 274]\n",
      " [303 538]]\n",
      "two_year_recid    0    1\n",
      "row_0                   \n",
      "0               567  303\n",
      "1               274  538\n",
      "random: \n",
      "[[561 280]\n",
      " [300 541]]\n",
      "two_year_recid    0    1\n",
      "row_0                   \n",
      "0               561  300\n",
      "1               280  541\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Confusion Matrix\n",
    "\n",
    "# 2.1 Create a confusion matrix that evaluates the performance of your model. What do you observe?\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_random = rf_random.predict(X_test)\n",
    "y_pred_grid = best_grid.predict(X_test)\n",
    "\n",
    "\n",
    "print('best grid: ')\n",
    "print(confusion_matrix(y_test, y_pred_grid))\n",
    "print(pd.crosstab(y_pred_grid, y_test)) # rows predicted, columns actual values (https://www.youtube.com/watch?v=42JGBd6zh8E)\n",
    "\n",
    "print('random: ')\n",
    "print(confusion_matrix(y_test, y_pred_random))\n",
    "print(pd.crosstab(y_pred_random, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.1: Confusion Matrix: What do you observe?**\n",
    "<br> quite a lot of Type 1 and Type 2 Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int64), array([574, 575], dtype=int64))\n",
      "(array([0, 1], dtype=int64), array([247, 246], dtype=int64))\n",
      "Caucasians best grid: \n",
      "[[206  41]\n",
      " [104 142]]\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          206   41\n",
      "1          104  142\n",
      "Caucasians random: \n",
      "[[203  44]\n",
      " [102 144]]\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          203   44\n",
      "1          102  144\n",
      "(array([0, 1], dtype=int64), array([1059, 1060], dtype=int64))\n",
      "(array([0, 1], dtype=int64), array([455, 454], dtype=int64))\n",
      "African_American best grid: \n",
      "[[269 186]\n",
      " [ 98 356]]\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          269  186\n",
      "1           98  356\n",
      "African_American random: \n",
      "[[269 186]\n",
      " [ 99 355]]\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          269  186\n",
      "1           99  355\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2.2 create a confusion matrix for specific groups:\n",
    "# 2.2.1 ake targets and predictions only for *Caucasians*,\n",
    "\n",
    "# a)\n",
    "# split the data set in train and test set (70/30 split) -> balanced data set grab equal amount of each target value\n",
    "# train_test_split by sklearn\n",
    "\n",
    "X_Caucasians = recidivism[recidivism.race_Caucasian == 1]\n",
    "X_Caucasians = X_Caucasians.drop(columns = ['two_year_recid'])\n",
    "#0 = defendant did not recommit a crime within two years; 1 = the defendant recommitted a crime within two years\n",
    "y_Caucasians = recidivism[recidivism.race_Caucasian == 1]\n",
    "y_Caucasians = y_Caucasians['two_year_recid']\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "X_res, y_res = rus.fit_resample(X_Caucasians, y_Caucasians)\n",
    "\n",
    "X_Caucasians_train, X_Caucasians_test, y_Caucasians_train, y_Caucasians_test = train_test_split(X_res, y_res, test_size=0.3, \\\n",
    "    stratify=y_res, random_state=42) \n",
    "\n",
    "# to check if equal amount of each target value \n",
    "print(np.unique(y_Caucasians_train, return_counts=True))\n",
    "print(np.unique(y_Caucasians_test, return_counts=True))\n",
    "\n",
    "y_Caucasians_pred_random = rf_random.predict(X_Caucasians_test)\n",
    "y_Caucasians_pred_grid = best_grid.predict(X_Caucasians_test)\n",
    "\n",
    "print('Caucasians best grid: ')\n",
    "print(confusion_matrix(y_Caucasians_test, y_Caucasians_pred_grid))\n",
    "print(pd.crosstab(y_Caucasians_test, y_Caucasians_pred_grid, rownames=['Actual'], colnames=['Predicted']))\n",
    "\n",
    "print('Caucasians random: ')\n",
    "print(confusion_matrix(y_Caucasians_test, y_Caucasians_pred_random))\n",
    "print(pd.crosstab(y_Caucasians_test, y_Caucasians_pred_random, rownames=['Actual'], colnames=['Predicted']))\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "# 2.2.2 Take targets and predictions only for *African-Americans*.\n",
    "\n",
    "X_African_American = recidivism.loc[recidivism['race_African-American'] == 1]\n",
    "X_African_American = X_African_American.drop(columns = ['two_year_recid'])\n",
    "#0 = defendant did not recommit a crime within two years; 1 = the defendant recommitted a crime within two years\n",
    "y_African_American = recidivism.loc[recidivism['race_African-American'] == 1]\n",
    "y_African_American = y_African_American['two_year_recid']\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
    "X_res, y_res = rus.fit_resample(X_African_American, y_African_American)\n",
    "\n",
    "X_African_American_train, X_African_American_test, y_African_American_train, y_African_American_test = \\\n",
    "    train_test_split(X_res, y_res, test_size=0.3, stratify=y_res, random_state=42) \n",
    "\n",
    "# to check if equal amount of each target value\n",
    "print(np.unique(y_African_American_train, return_counts=True))\n",
    "print(np.unique(y_African_American_test, return_counts=True))\n",
    "\n",
    "y_African_American_pred_random = rf_random.predict(X_African_American_test)\n",
    "y_African_American_pred_grid = best_grid.predict(X_African_American_test)\n",
    "\n",
    "print('African_American best grid: ')\n",
    "print(confusion_matrix(y_African_American_test, y_African_American_pred_grid))\n",
    "print(pd.crosstab(y_African_American_test, y_African_American_pred_grid, rownames=['Actual'], colnames=['Predicted']))\n",
    "\n",
    "print('African_American random: ')\n",
    "print(confusion_matrix(y_African_American_test, y_African_American_pred_random))\n",
    "print(pd.crosstab(y_African_American_test, y_African_American_pred_random, rownames=['Actual'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.3 What do you see when you compare the two confusion matrices? Explain in your own words how this might affect the overall fairness of your model.**\n",
    "<br> Caucasian -> majority Type 2 Error [-> the model predicts falsely a recommitted crime by Caucasian??]\n",
    "<br> African American -> majority Type 1 Error [-> the model does not predict a recommitted crimes by African Americans when there are some??]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fairness and bias in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try to fix our model, let's understand bias better and get some intuition about it. In the video below I summarize different types of bias. \n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/tcz800ZXclA/0.jpg)](https://www.youtube.com/watch?v=tcz800ZXclA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Exercise 3.1:* Have you watched the video? A few questions to make sure you did.\n",
    "> * What does **data bias** mean?\n",
    "\n",
    "<br> \"Data is not representative of the population or phenomenon of study.\n",
    "<br>  Data does not include variables that properly capture the phenomenon we want to predit.\n",
    "<br>  Data includes content produced by humans which may contain bias against groups of people.\"\n",
    "\n",
    "> * What are the most common types of data bias? \n",
    "\n",
    "<br> 1. Response and Activity Bias\n",
    "<br> 2. Selection bias due to feedback loops\n",
    "<br> 3. Bias due to system drift\n",
    "<br> 4. Omitted variable bias\n",
    "<br> 5. Societal Bias\n",
    "\n",
    "> * Choose two types of data bias and explain them by also providing some examples.\n",
    "\n",
    "<br> \"1. Response and Activity Bias -> occurs in contend by humans (e.g. reviews on Amazon, tweets, posts on e.g. Facebook, Wikipedia entries...) -> bias: most data comes from a few sources, limited population, majority of users represent only a few demographic groups and geographic areas (e.g. 50% of Amazon reviews by 4% of the users)\n",
    "<br> 2. Selection bias due to feedback loops -> occurs when a model itself influences the generation of data that is used to train it -> Bias: ML models direct user attention to a small subset of items, ML models record user actions on these items, this bias occurs due to the non-random subset of the items presented to users\n",
    "<br> 3. Bias due to system drift -> occurs when the system generating the data goes through changes over time -> Bias: concept drift: the definition of the target changes (e.g. change in the definition of fraud?), model drift: the way users interact changes (e.g. introduction of recommended searches in google -> more searches on similar topic)\n",
    "<br> 4. Omitted variable bias -> occurs in data in which critical attributes that influence the outcome are missing -> Bias: Data generated by humans not recording certain info due to lack of access/ privacy, omitted variable is correlated with target, omitted variable is also corrlated with one or more predictor variables\n",
    "<br> 5. Societal Bias -> occurs in content produced by humans, whether it be social media content or curated news articles -> Bias: data inherently contains bias and stereotypes, models trained on data discriminate on race, gender, or other categories.\"\n",
    "\n",
    "**Examples are missing**\n",
    "\n",
    "> * How can data bias be identified? \n",
    "\n",
    "<br> \"understand how the data was generated, perform comprehensive exploratory data analysis\"\n",
    "\n",
    "> * At what step of the process can we correct for bias?\n",
    "\n",
    "<br> \"correct model at the pre-processing/ in-processing/ post-processing step\"\n",
    "\n",
    "> * What do you think are the potential bias sources in our case-study (i.e. recidivism)?\n",
    "\n",
    "<br> the data itself\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we know a bit more about bias... but how do we correct it in practice? There are many ways, and you are going to test a couple of methods to correct the predictions on recidivism to enhance the fairness of your model.\n",
    "\n",
    "Germans and I had a nice chat about it and recorded a video to introduce you with two methods: *Demographic Pairity* and *Equal Odds*!\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/DHz1xDKT4xw/0.jpg)](https://www.youtube.com/watch?v=DHz1xDKT4xw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercises we are going to focus only on the *African-American* and *Caucasian* groups as they have more data samples in our data (however, you can repeat the steps for other demographics too!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercise 3.2:* Demographic Parity. In this exercise, we are going to implement the function for Demographic Parity and apply it to the results of your ML model (i.e. on the predictions of the Test set).\n",
    ">\n",
    "> * Compute the probability of predicting recidivism ($\\hat{y}=1$) for the two populations, i.e. $P_{AA}$ for African-American and $P_{CA}$ for Caucasian. What do you observe?\n",
    "> * To debias the output you need to:\n",
    ">    * Compute the threshold as $th = 1 - \\frac{P_{CA}}{P_{AA}}$;\n",
    ">    * randomly flip positive prediction to negative (1s to 0s), i.e. pick a random number $n\\in\\left[0,1\\right)$ from a uniform distribution and flip a positive prediction if $n < th$.\n",
    "> * Recompute the probabilities $P_{CA}$ and $P_{AA}$ (only now they are corrected). What do you observe?\n",
    "> * Plot the confusion matrices with the corrected values. What do you observe?\n",
    "> * Explain what could be the issue with this method. We have discussed it in the video ðŸ˜‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_AA = 0.5951595159515951, P_CA = 0.3813387423935091\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.2.1\n",
    "\n",
    "P_AA = len(y_African_American_pred_random[y_African_American_pred_random == 1])/len(y_African_American_pred_random)\n",
    "P_CA = len(y_Caucasians_pred_random[y_Caucasians_pred_random == 1])/len(y_Caucasians_pred_random)\n",
    "print(f'P_AA = {P_AA}, P_CA = {P_CA}')\n",
    "# 0 = defendant did not recommit a crime within two years; 1 = the defendant recommitted a crime within two years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you observe?**\n",
    "<br> significant higher probability for African American people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.35926632747560105\n",
      "P_AA: 0.86, P_CA: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.2.2 -> threshold + flipping\n",
    "import random\n",
    "\n",
    "# threshold\n",
    "th = 1- (P_CA/ P_AA)\n",
    "print(f'Threshold = {th}')\n",
    "\n",
    "# randomly flipping of positive predictions to negative until equal probability (99% sure that this is wrong!)\n",
    "\n",
    "y_Caucasians_pred_random_demo_parity = np.copy(y_Caucasians_pred_random)\n",
    "y_African_American_pred_random_demo_parity = np.copy(y_African_American_pred_random)\n",
    "P_CA_demo_parity = np.copy(P_CA)\n",
    "P_AA_demo_parity = np.copy(P_AA)\n",
    "\n",
    "while np.round(P_AA_demo_parity,2) != np.round(P_CA_demo_parity,2):\n",
    "\n",
    "    n = np.random.uniform(0,1,1)\n",
    "\n",
    "    if n < th:\n",
    "        choice = random.choice(['Caucasian', 'African_American'])\n",
    "\n",
    "        if choice == 'Caucasian':\n",
    "\n",
    "            indices = np.where(y_Caucasians_pred_random_demo_parity==0)[0]\n",
    "            y_Caucasians_pred_random_demo_parity[random.choice(indices)] = 1\n",
    "                \n",
    "        else:\n",
    "\n",
    "            indices = np.where(y_African_American_pred_random_demo_parity==0)[0]\n",
    "            y_African_American_pred_random_demo_parity[random.choice(indices)] = 1\n",
    "      \n",
    "    P_AA_demo_parity = len(y_African_American_pred_random_demo_parity[y_African_American_pred_random_demo_parity == 1])/len(\\\n",
    "        y_African_American_pred_random_demo_parity)\n",
    "    P_CA_demo_parity = len(y_Caucasians_pred_random_demo_parity[y_Caucasians_pred_random_demo_parity == 1])/len(\\\n",
    "        y_Caucasians_pred_random_demo_parity)\n",
    "\n",
    "print(f'P_AA: {np.round(P_AA_demo_parity,2)}, P_CA: {np.round(P_CA_demo_parity,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.3 Recompute the probabilities $P_{CA}$ and $P_{AA}$ (only now they are corrected). What do you observe?**\n",
    "<pr> 0.86 is a really high probability -> almost all the people would recommit a crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity Caucasians: \n",
      "Predicted   0    1\n",
      "Actual            \n",
      "0          47  200\n",
      "1          24  222\n",
      "Demographic Parity African American: \n",
      "Predicted   0    1\n",
      "Actual            \n",
      "0          91  364\n",
      "1          38  416\n"
     ]
    }
   ],
   "source": [
    "# 3.2.4 Confusion Matrix for new probabilities\n",
    "\n",
    "print('Demographic Parity Caucasians: ')\n",
    "print(pd.crosstab(y_Caucasians_test, y_Caucasians_pred_random_demo_parity, rownames=['Actual'], colnames=['Predicted']))\n",
    "\n",
    "print('Demographic Parity African American: ')\n",
    "print(pd.crosstab(y_African_American_test, y_African_American_pred_random_demo_parity, rownames=['Actual'], colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.5 Explain what could be the issue with this method.**\n",
    "<br> a lot of Type 1 Errors\n",
    "<br> by randomly assigning more recommitted crimes -> the total amount rises in both ethnical groups -> for the algorithm it seems now like there are more recommitted crimes within these groups -> the algorithm assumes it is more likely by them to recommit a crime, also the comparison to the other ethnical groups is changed\n",
    "<br> you are not choosing based on any features/ feature combination, but randomly until the probabilities are equal\n",
    "<br> or it might be more likely that one ethnical group commits more crimes? \n",
    "<br> maybe by adjusting the probabilities, we kind of assume that the same features/ feature combinations of the larger sample group lead to the same result in the smaller group? might be right might be wrong\n",
    "\n",
    "\n",
    "<br> **#We have discussed it in the video ðŸ˜‰**????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "You are almost there! In the following you will use the Equal Odds method to correct your predictions. It seems long, but don't worry it is because I added a bit more code, steps, hints for this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercise 3.3:* Equal Odds. As in the exercise above we are going to use the results of you ML model on the test set.\n",
    "> * This method takes into account the predictions of your model $\\hat{y}$ for different thresholds $th$:\n",
    ">    * Get the probabilities out of your model by using `y_prob = model.predict_proba(X_test)` (here, `model` is your model).\n",
    ">    * Define the thresholds as `ths = np.linspace(1e-5,1-1e-5, 10)` (you can edit this one to have different thresholds). Now, you can find $\\hat{y}$ as:\n",
    ">\n",
    ">\n",
    ">$$\\begin{cases}\\hat{y}=1, \\mbox{ if } y_{prob} > th \\\\ \\hat{y}=0, \\mbox{ otherwhise}\\end{cases}$$\n",
    ">\n",
    ">\n",
    "> * Implement a function that takes as an input $y$ (i.e the target labels), $\\hat{y}$, and `ths` and returns the true-positive rate $TPR$ and the false-positive rate $FPR$ (definitions in the video above).\n",
    "> * Now, you need to find the thresholds that lead to the closest points for the two groups on the [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic). The first way is by using the functions below in your code to find the thresholds that lead to the smaller distance (**but suitable FPR and TPR**):\n",
    "> ```python\n",
    "    #This function takes as an input y, y_probs, thr \n",
    "    #and returns the points to plot the ROC curve and their threshold\n",
    "    def roc_curve(y, y_probs, ths):\n",
    "        #initialize roc as an empty np.array\n",
    "        roc = np.array([])\n",
    "        #loop over thresholds\n",
    "        for th in ths:\n",
    "          #convert y_prob in y_hat\n",
    "          y_hat = ADD_YOUR_FUNCTION_HERE(y_prob,th)\n",
    "          #compute TPR and FPR\n",
    "          TPR, FPR = ADD_YOUR_FUNCTION_HERE(y, y_hat)\n",
    "          #add threshold and point to roc array\n",
    "          roc = np.append(roc, [th, FPR, TPR])\n",
    "       #return roc\n",
    "       return roc.reshape(-1, 3)\n",
    "> ```\n",
    "> ```python\n",
    "    #This function takes as an input the points from one roc (first group) and the other (second group) and order the points by their distance in ascending order \n",
    "    def closest_points(points1, points2):\n",
    "        #initialize result\n",
    "        res = list()\n",
    "        #loop over points in group 1\n",
    "        for pi in points1:\n",
    "          #loop over points in group 2\n",
    "          for pj in points2:\n",
    "            #add points and their distance to res\n",
    "            res.append(((pi, pj), np.linalg.norm(pi[1:] - pj[1:])))\n",
    "        #return sorted result\n",
    "        return sorted(res, key = lambda x: x[1])\n",
    "> ```\n",
    "> * The second way is by visualizing the ROC curves. Let's do it with Bokeh:\n",
    ">     * Get the two ROC curves with the function `roc_curve` above and call them `roc_aa` (for African-Americans) and `roc_ca` (for Caucasian).\n",
    ">     * Create a `DataFrame` called `df_roc` with columns `FPR_AA`, `TPR_AA`, `FPR_CA`, `TPR_CA`, with the FPR and TPR values for both groups. Convert the dataframe into a Bokeh `ColumnDataSource`.\n",
    ">     * Create an empty bokeh figure and add labels and title (we will have FPR on the x-axis and TPR on the y-axis)\n",
    ">     * Add two `p.line()` by passing the values from your dataframe for one group and then the other. You should now see the plot with both lines. Use colors and other parameters to customize it as you like\n",
    ">     * Finally, we need to add one last thing: interactive points that will show the thresholds. The easiest way I found to do this was to create a second `DataFrame` with columns `x`, `y`, `th` where x is the combined list of `FPR_AA` and `FPR_CA`, y is the combined list of `TPR_AA` and `TPR_CA`, and th is the threshold list repeated twice. Convert this dataframe into a Bokeh `ColumnDataSource` as usual and add the points to the plot with \n",
    "> ```python\n",
    "> cr = p.circle('x','y',source=..., fill_color=..., hover_fill_color=...) \n",
    "> ````\n",
    "> you can make them interactive by adding the following line of code:\n",
    "> ```python \n",
    ">    p.add_tools(HoverTool(tooltips=[('Threshold', '@th')], renderers=[cr]))\n",
    "> ```\n",
    "> * Use the two methods above to find a threshold for each group. What threshold did you find?\n",
    "> * Debias the output by computing $\\hat{y}$ for the two groups with the thresholds you found. Now plot the confusion matrices for African-Americans and Caucasian again. What do you observe? \n",
    "> * We ended the video by saying that there might be still a problem with the methods we have used to de-bias data. What do you think the problem is? **Hint**: it is related to the [following article](https://en.wikipedia.org/wiki/Protected_group). Skim through it to get an idea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.3 Equal Odds\n",
    "\n",
    "# Exercise 3.3.1\n",
    "\n",
    "# probabilities\n",
    "y_Causiansian_prob = rf_random.predict_proba(X_Caucasians_test)[:,1] # probability for predicting one\n",
    "y_African_American_prob = rf_random.predict_proba(X_African_American_test)[:,1]\n",
    "# best_grid.classes_ -> to check order of the labels\n",
    "\n",
    "# define thresholds\n",
    "ths = np.linspace(1e-5,1-1e-5, 10)\n",
    "\n",
    "# calculate y_pred for all thresholds based on:\n",
    "\n",
    "# y_pred = 1 if y_prob > ths\n",
    "# y_pred = 0, otherwise\n",
    "\n",
    "# ich baue eine Matrix -> erste spalte = 1. threshold etc.\n",
    "\n",
    "def auc_roc_graph_array(thresholds, y_pred, y_prob):\n",
    "\n",
    "    result_array = np.zeros((len(y_pred),len(thresholds)))\n",
    "\n",
    "    for counter, threshold in enumerate(thresholds):\n",
    "       \n",
    "        for i, _ in enumerate(y_pred):\n",
    "\n",
    "            y_pred_threshold = np.copy(y_pred)\n",
    "\n",
    "            if y_prob[i] > threshold:\n",
    "                y_pred_threshold[i] = 1\n",
    "            else:\n",
    "                y_pred_threshold[i] = 0\n",
    "    \n",
    "        result_array[:, counter] = np.copy(y_pred_threshold)\n",
    "\n",
    "    return(result_array)\n",
    "\n",
    "Caucasians_auc_roc_graph_array = auc_roc_graph_array(ths, y_Caucasians_pred_random, y_Causiansian_prob)\n",
    "African_American_auc_roc_graph_array = auc_roc_graph_array(ths, y_African_American_pred_random, y_African_American_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR Caucasians: [0.58536585 0.58536585 0.58536585 0.58536585 0.58536585 0.58536585\n",
      " 0.58536585 0.58536585 0.58536585 0.58536585]\n",
      "FPR Caucasians: [0.18218623 0.18218623 0.18218623 0.17813765 0.17813765 0.17813765\n",
      " 0.17813765 0.17813765 0.17813765 0.17813765]\n",
      "TPR African_American: [0.78193833 0.78193833 0.78193833 0.78193833 0.78193833 0.78193833\n",
      " 0.78193833 0.78193833 0.78193833 0.78193833]\n",
      "FPR African_American: [0.40879121 0.40879121 0.40879121 0.40879121 0.40879121 0.40879121\n",
      " 0.40879121 0.40879121 0.40659341 0.40659341]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.3.2 \n",
    " \n",
    "# function to compute TPR and FPR (input y_test, y_pred, ths)\n",
    "\n",
    "def TPR_FPR(auc_roc_graph_array, y_test):\n",
    "\n",
    "    y_test = y_test.values\n",
    "\n",
    "    TPR = np.zeros(auc_roc_graph_array.shape[1])\n",
    "    FPR = np.zeros(auc_roc_graph_array.shape[1])\n",
    "\n",
    "    for threshold in range(auc_roc_graph_array.shape[1]):\n",
    "\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "\n",
    "        for y_pred_index in range(auc_roc_graph_array.shape[0]):\n",
    " \n",
    "            if y_test[y_pred_index]==auc_roc_graph_array[y_pred_index, threshold]==1:\n",
    "                TP += 1\n",
    "            elif auc_roc_graph_array[y_pred_index, threshold]==1 and y_test[y_pred_index]!=auc_roc_graph_array[y_pred_index, threshold]:\n",
    "                FP += 1\n",
    "            elif y_test[y_pred_index]==auc_roc_graph_array[y_pred_index, threshold]==0:\n",
    "                TN += 1\n",
    "            elif auc_roc_graph_array[y_pred_index, threshold]==0 and y_test[y_pred_index]!=auc_roc_graph_array[y_pred_index, threshold]:\n",
    "                FN += 1\n",
    "\n",
    "        TPR[threshold] = TP/(TP + FN)\n",
    "        FPR[threshold] = FP/(FP + TN)\n",
    "\n",
    "    return(TPR, FPR)\n",
    "\n",
    "\n",
    "Caucasians_TPR_FPR = TPR_FPR(Caucasians_auc_roc_graph_array, y_Caucasians_test)\n",
    "African_American_TPR_FPR = TPR_FPR(African_American_auc_roc_graph_array, y_African_American_test)\n",
    "\n",
    "print(f'TPR Caucasians: {Caucasians_TPR_FPR[0]}')\n",
    "print(f'FPR Caucasians: {Caucasians_TPR_FPR[1]}')\n",
    "print(f'TPR African_American: {African_American_TPR_FPR[0]}')\n",
    "print(f'FPR African_American: {African_American_TPR_FPR[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! It is now time for you to have a break, relax and be proud of the awesome work you have done!! But before you go, please <mark> take a minute of your time (it is really one minute) to fill this [form](https://forms.gle/fbUXFxmJ283cKGvy6). Thank you so much! </mark>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
